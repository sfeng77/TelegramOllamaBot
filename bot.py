import os
import json
import logging
import time
import aiohttp
from dotenv import load_dotenv
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes, CallbackQueryHandler

# é…ç½®æ—¥å¿—
import logging.handlers

# åˆ›å»ºæ—¥å¿—ç›®å½•
import os
log_dir = "logs"
if not os.path.exists(log_dir):
    os.makedirs(log_dir)

# é…ç½®æ ¹æ—¥å¿—å™¨
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # æ§åˆ¶å°è¾“å‡º
        logging.handlers.RotatingFileHandler(
            os.path.join(log_dir, 'bot.log'),
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5,
            encoding='utf-8'
        )
    ]
)

# åˆ›å»ºä¸“é—¨çš„å¯¹è¯æ—¥å¿—å™¨
conversation_logger = logging.getLogger('conversation')
conversation_handler = logging.handlers.RotatingFileHandler(
    os.path.join(log_dir, 'conversations.log'),
    maxBytes=10*1024*1024,  # 10MB
    backupCount=5,
    encoding='utf-8'
)
conversation_formatter = logging.Formatter('%(asctime)s - %(message)s')
conversation_handler.setFormatter(conversation_formatter)
conversation_logger.addHandler(conversation_handler)
conversation_logger.setLevel(logging.INFO)

logger = logging.getLogger(__name__)

def split_long_message(text: str, max_length: int = 4000) -> list[str]:
    """å°†é•¿æ¶ˆæ¯åˆ†å‰²æˆå¤šä¸ªè¾ƒçŸ­çš„æ¶ˆæ¯"""
    if len(text) <= max_length:
        return [text]
    
    messages = []
    current_message = ""
    
    # æŒ‰æ®µè½åˆ†å‰²
    paragraphs = text.split('\n\n')
    
    for paragraph in paragraphs:
        # å¦‚æœå½“å‰æ®µè½åŠ ä¸Šå½“å‰æ¶ˆæ¯è¶…è¿‡é™åˆ¶
        if len(current_message) + len(paragraph) + 2 > max_length:
            if current_message:
                messages.append(current_message.strip())
                current_message = paragraph
            else:
                # å¦‚æœå•ä¸ªæ®µè½å°±è¶…è¿‡é™åˆ¶ï¼ŒæŒ‰å¥å­åˆ†å‰²
                sentences = paragraph.split('. ')
                for sentence in sentences:
                    if len(current_message) + len(sentence) + 2 > max_length:
                        if current_message:
                            messages.append(current_message.strip())
                        current_message = sentence
                    else:
                        current_message += ". " + sentence if current_message else sentence
        else:
            current_message += "\n\n" + paragraph if current_message else paragraph
    
    if current_message:
        messages.append(current_message.strip())
    
    return messages

async def send_long_message(update: Update, text: str, max_length: int = 4000):
    """å‘é€å¯èƒ½å¾ˆé•¿çš„æ¶ˆæ¯ï¼Œè‡ªåŠ¨åˆ†å‰²"""
    messages = split_long_message(text, max_length)
    
    for i, message in enumerate(messages):
        if i == 0:
            # ç¬¬ä¸€æ¡æ¶ˆæ¯ç›´æ¥å›å¤
            await update.message.reply_text(message)
        else:
            # åç»­æ¶ˆæ¯ä½œä¸ºæ–°æ¶ˆæ¯å‘é€
            await update.message.reply_text(f"ï¼ˆç»­ {i+1}/{len(messages)}ï¼‰\n\n{message}")
        
        # æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…å‘é€è¿‡å¿«
        if i < len(messages) - 1:
            import asyncio
            await asyncio.sleep(0.5)
    
    # è®°å½•é•¿æ¶ˆæ¯åˆ†å‰²æƒ…å†µ
    if len(messages) > 1:
        logger.info(f"é•¿æ¶ˆæ¯å·²åˆ†å‰²ä¸º {len(messages)} æ¡æ¶ˆæ¯å‘é€")

async def send_ai_response(update: Update, ai_response: str, time_str: str):
    """ä¸“é—¨ç”¨äºå‘é€AIå›å¤çš„å‡½æ•°ï¼Œç¡®ä¿æ—¶é—´ä¿¡æ¯æ­£ç¡®æ˜¾ç¤º"""
    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å‰²
    full_response = f"{ai_response}\n\nâ±ï¸ ç”Ÿæˆæ—¶é—´ï¼š{time_str}"
    
    if len(full_response) <= 4000:
        # æ¶ˆæ¯ä¸é•¿ï¼Œç›´æ¥å‘é€
        await update.message.reply_text(full_response)
    else:
        # æ¶ˆæ¯å¤ªé•¿ï¼Œéœ€è¦åˆ†å‰²
        # å…ˆå‘é€AIå›å¤å†…å®¹
        ai_messages = split_long_message(ai_response, 4000)
        
        for i, message in enumerate(ai_messages):
            if i == 0:
                await update.message.reply_text(message)
            else:
                await update.message.reply_text(f"ï¼ˆç»­ {i+1}/{len(ai_messages)}ï¼‰\n\n{message}")
            
            # æ·»åŠ å»¶è¿Ÿ
            if i < len(ai_messages) - 1:
                import asyncio
                await asyncio.sleep(0.5)
        
        # æœ€åå‘é€æ—¶é—´ä¿¡æ¯
        await update.message.reply_text(f"â±ï¸ ç”Ÿæˆæ—¶é—´ï¼š{time_str}")
        
        logger.info(f"AIå›å¤å·²åˆ†å‰²ä¸º {len(ai_messages)} æ¡æ¶ˆæ¯ + æ—¶é—´ä¿¡æ¯å‘é€")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
OLLAMA_API_URL = "http://localhost:11434/api/generate"

# å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
AVAILABLE_MODELS = {
    # 'deepseek_small': 'deepseek-r1:1.5b',
    # 'deepseek_large': 'deepseek-r1:32b',
    # 'llama2': 'llama2',
    # 'llama2-uncensored': 'llama2-uncensored',
    # 'mistral': 'mistral',
    # 'neural-chat': 'neural-chat',
    'gpt-oss:20b': 'gpt-oss:20b'
}

# é»˜è®¤æ¨¡å‹
DEFAULT_MODEL = 'gpt-oss:20b'

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç† /start å‘½ä»¤"""
    user_id = update.effective_user.id
    username = update.effective_user.username or "Unknown"
    
    # åˆå§‹åŒ–ç”¨æˆ·è®¾ç½®
    if not context.user_data.get('model'):
        context.user_data['model'] = DEFAULT_MODEL
    
    # åˆå§‹åŒ–å¯¹è¯å†å²
    if not context.user_data.get('conversation_history'):
        context.user_data['conversation_history'] = []

    logger.info(f"ç”¨æˆ· {username}({user_id}) æ‰§è¡Œ/startå‘½ä»¤")
    conversation_logger.info(f"[ç”¨æˆ· {username}({user_id})] æ‰§è¡Œ/startå‘½ä»¤ - åˆå§‹åŒ–å¯¹è¯")

    welcome_message = """
æ¬¢è¿ä½¿ç”¨ AI èŠå¤©æœºå™¨äººï¼

è¿™ä¸ªæœºå™¨äººä½¿ç”¨ Ollama æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚
å½“å‰ä½¿ç”¨çš„æ¨¡å‹æ˜¯ï¼š{}

å‘½ä»¤åˆ—è¡¨ï¼š
/start - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
/help - è·å–å¸®åŠ©
/model - é€‰æ‹© AI æ¨¡å‹
/forget - å¿˜è®°ä¹‹å‰çš„å¯¹è¯å†…å®¹
""".format(AVAILABLE_MODELS[context.user_data['model']])
    await send_long_message(update, welcome_message)

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç† /help å‘½ä»¤"""
    help_text = """
ä½¿ç”¨è¯´æ˜ï¼š

1. ç›´æ¥å‘é€æ–‡å­—æ¶ˆæ¯å³å¯ä¸ AI å¯¹è¯
2. æœºå™¨äººä¼šè®°ä½å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œæä¾›æ›´è¿è´¯çš„å¯¹è¯ä½“éªŒ
3. ä½¿ç”¨ /model å‘½ä»¤å¯ä»¥åˆ‡æ¢ä¸åŒçš„ AI æ¨¡å‹
4. ä½¿ç”¨ /forget å‘½ä»¤å¯ä»¥æ¸…é™¤å¯¹è¯å†å²ï¼Œé‡æ–°å¼€å§‹
5. å½“å‰æ”¯æŒçš„æ¨¡å‹ï¼š
{}
6. å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·å°è¯•é‡æ–°å‘é€æ¶ˆæ¯
7. å¦‚éœ€é‡æ–°å¼€å§‹å¯¹è¯ï¼Œè¯·ä½¿ç”¨ /start å‘½ä»¤
""".format('\n'.join(f'   - {name}: {model}' for name, model in AVAILABLE_MODELS.items()))
    await send_long_message(update, help_text)

async def model_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç† /model å‘½ä»¤"""
    user_id = update.effective_user.id
    username = update.effective_user.username or "Unknown"
    current_model = context.user_data.get('model', DEFAULT_MODEL)
    
    logger.info(f"ç”¨æˆ· {username}({user_id}) æ‰§è¡Œ/modelå‘½ä»¤ - å½“å‰æ¨¡å‹: {current_model}")
    
    keyboard = []
    # åˆ›å»ºæ¨¡å‹é€‰æ‹©æŒ‰é’®
    for name, model in AVAILABLE_MODELS.items():
        # åœ¨å½“å‰é€‰ä¸­çš„æ¨¡å‹æ—è¾¹æ·»åŠ æ ‡è®°
        current = 'âœ“ ' if context.user_data.get('model') == name else ''
        keyboard.append([InlineKeyboardButton(f"{current}{model}", callback_data=f"model_{name}")])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text('è¯·é€‰æ‹©è¦ä½¿ç”¨çš„ AI æ¨¡å‹ï¼š', reply_markup=reply_markup)

async def forget_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç† /forget å‘½ä»¤"""
    user_id = update.effective_user.id
    username = update.effective_user.username or "Unknown"
    
    # è®°å½•æ¸…é™¤å‰çš„å†å²é•¿åº¦
    history_length = len(context.user_data.get('conversation_history', []))
    
    # æ¸…é™¤å¯¹è¯å†å²
    context.user_data['conversation_history'] = []
    
    # è®°å½•æ¸…é™¤æ“ä½œ
    logger.info(f"ç”¨æˆ· {username}({user_id}) æ‰§è¡Œ/forgetå‘½ä»¤ - æ¸…é™¤äº†{history_length}è½®å¯¹è¯å†å²")
    conversation_logger.info(f"[ç”¨æˆ· {username}({user_id})] æ‰§è¡Œ/forgetå‘½ä»¤ - æ¸…é™¤äº†{history_length}è½®å¯¹è¯å†å²")
    
    await update.message.reply_text("ğŸ§¹ å·²æ¸…é™¤æ‰€æœ‰å¯¹è¯å†å²ï¼Œæˆ‘ä»¬å¯ä»¥é‡æ–°å¼€å§‹å¯¹è¯äº†ï¼")

async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç†æŒ‰é’®å›è°ƒ"""
    query = update.callback_query
    user_id = update.effective_user.id
    username = update.effective_user.username or "Unknown"
    
    await query.answer()

    if query.data.startswith('model_'):
        model_name = query.data[6:]  # ç§»é™¤ 'model_' å‰ç¼€
        if model_name in AVAILABLE_MODELS:
            old_model = context.user_data.get('model', DEFAULT_MODEL)
            context.user_data['model'] = model_name
            new_model = AVAILABLE_MODELS[model_name]
            
            logger.info(f"ç”¨æˆ· {username}({user_id}) åˆ‡æ¢æ¨¡å‹: {old_model} -> {model_name}")
            conversation_logger.info(f"[ç”¨æˆ· {username}({user_id})] åˆ‡æ¢æ¨¡å‹: {old_model} -> {new_model}")
            
            await query.edit_message_text(f'å·²åˆ‡æ¢åˆ°æ¨¡å‹ï¼š{new_model}')
        else:
            logger.warning(f"ç”¨æˆ· {username}({user_id}) å°è¯•é€‰æ‹©æ— æ•ˆæ¨¡å‹: {model_name}")
            await query.edit_message_text('æ— æ•ˆçš„æ¨¡å‹é€‰æ‹©')

async def query_ollama(prompt: str, model: str, context_history: list = None) -> tuple[str, float]:
    """å‘ Ollama API å‘é€è¯·æ±‚ï¼Œè¿”å›å›å¤å’Œç”Ÿæˆæ—¶é—´"""
    start_time = time.time()
    
    # æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„å®Œæ•´æç¤º
    if context_history and len(context_history) > 0:
        # å°†å†å²å¯¹è¯è½¬æ¢ä¸ºä¸Šä¸‹æ–‡æ ¼å¼
        context_text = "\n".join([f"ç”¨æˆ·: {item['user']}\nåŠ©æ‰‹: {item['assistant']}" for item in context_history[-10:]])  # åªä¿ç•™æœ€è¿‘10è½®å¯¹è¯
        full_prompt = f"ä»¥ä¸‹æ˜¯ä¹‹å‰çš„å¯¹è¯å†å²ï¼š\n{context_text}\n\nç°åœ¨ç”¨æˆ·è¯´ï¼š{prompt}\nè¯·æ ¹æ®ä¸Šä¸‹æ–‡å›ç­”ï¼š"
        logger.info(f"å‘é€APIè¯·æ±‚åˆ°Ollama - æ¨¡å‹: {model}, åŒ…å«{len(context_history)}è½®å†å²å¯¹è¯")
    else:
        full_prompt = prompt
        logger.info(f"å‘é€APIè¯·æ±‚åˆ°Ollama - æ¨¡å‹: {model}, æ— å†å²å¯¹è¯")
    
    async with aiohttp.ClientSession() as session:
        try:
            async with session.post(
                OLLAMA_API_URL,
                json={
                    "model": model,
                    "prompt": full_prompt,
                    "stream": False
                }
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    end_time = time.time()
                    generation_time = end_time - start_time
                    response_text = result.get('response', 'æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚')
                    logger.info(f"Ollama APIå“åº”æˆåŠŸ - æ¨¡å‹: {model}, å“åº”æ—¶é—´: {generation_time:.2f}s, å“åº”é•¿åº¦: {len(response_text)}å­—ç¬¦")
                    return response_text, generation_time
                else:
                    end_time = time.time()
                    generation_time = end_time - start_time
                    error_msg = f"API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status}"
                    logger.error(f"Ollama APIè¯·æ±‚å¤±è´¥ - æ¨¡å‹: {model}, çŠ¶æ€ç : {response.status}, å“åº”æ—¶é—´: {generation_time:.2f}s")
                    return error_msg, generation_time
        except Exception as e:
            logger.error(f"è¯·æ±‚ Ollama API æ—¶å‡ºé”™: {str(e)}")
            end_time = time.time()
            generation_time = end_time - start_time
            error_msg = "æŠ±æ­‰ï¼Œä¸ AI æ¨¡å‹é€šä¿¡æ—¶å‡ºç°é”™è¯¯ã€‚è¯·ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œã€‚"
            logger.error(f"Ollama APIå¼‚å¸¸ - æ¨¡å‹: {model}, é”™è¯¯: {str(e)}, å“åº”æ—¶é—´: {generation_time:.2f}s")
            return error_msg, generation_time

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
    # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦å­˜åœ¨ä¸”ä¸ºæ–‡æœ¬æ¶ˆæ¯
    if not update.message or not update.message.text:
        if update.message:
            # å¦‚æœæ˜¯éæ–‡æœ¬æ¶ˆæ¯ï¼Œå›å¤æç¤º
            await update.message.reply_text("æŠ±æ­‰ï¼Œæˆ‘åªå¤„ç†æ–‡æœ¬æ¶ˆæ¯ã€‚è¯·å‘é€æ–‡å­—å†…å®¹ã€‚")
        return
    
    user_message = update.message.text
    user_id = update.effective_user.id
    username = update.effective_user.username or "Unknown"
    
    # ç¡®ä¿ç”¨æˆ·æœ‰é€‰æ‹©çš„æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹
    if not context.user_data.get('model'):
        context.user_data['model'] = DEFAULT_MODEL
    
    # ç¡®ä¿ç”¨æˆ·æœ‰å¯¹è¯å†å²ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆå§‹åŒ–
    if not context.user_data.get('conversation_history'):
        context.user_data['conversation_history'] = []
    
    current_model = AVAILABLE_MODELS[context.user_data['model']]
    conversation_history = context.user_data['conversation_history']
    conversation_round = len(conversation_history) + 1
    
    # è®°å½•ç”¨æˆ·æ¶ˆæ¯
    logger.info(f"ç”¨æˆ· {username}({user_id}) å‘é€æ¶ˆæ¯ - ç¬¬{conversation_round}è½®å¯¹è¯")
    conversation_logger.info(f"[ç”¨æˆ· {username}({user_id})] ç¬¬{conversation_round}è½® - ç”¨æˆ·: {user_message}")
    
    # å‘é€"æ­£åœ¨æ€è€ƒ"æ¶ˆæ¯
    thinking_message = await update.message.reply_text(
        f"æ­£åœ¨æ€è€ƒ...\nä½¿ç”¨æ¨¡å‹ï¼š{current_model}"
    )
    
    try:
        # è·å– AI å›å¤å’Œç”Ÿæˆæ—¶é—´ï¼Œä¼ é€’å¯¹è¯å†å²
        ai_response, generation_time = await query_ollama(user_message, current_model, conversation_history)
        
        # åˆ é™¤"æ­£åœ¨æ€è€ƒ"æ¶ˆæ¯
        await thinking_message.delete()
        
        # è®°å½•AIå›å¤
        logger.info(f"AIå›å¤ç”Ÿæˆå®Œæˆ - ç”¨æˆ·: {username}({user_id}), æ¨¡å‹: {current_model}, æ—¶é—´: {generation_time:.2f}s")
        conversation_logger.info(f"[ç”¨æˆ· {username}({user_id})] ç¬¬{conversation_round}è½® - AIå›å¤: {ai_response}")
        
        # å°†å½“å‰å¯¹è¯æ·»åŠ åˆ°å†å²è®°å½•ä¸­
        conversation_history.append({
            'user': user_message,
            'assistant': ai_response
        })
        
        # é™åˆ¶å†å²è®°å½•é•¿åº¦ï¼Œé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿
        if len(conversation_history) > 20:  # ä¿ç•™æœ€è¿‘20è½®å¯¹è¯
            conversation_history = conversation_history[-20:]
            context.user_data['conversation_history'] = conversation_history
            logger.info(f"ç”¨æˆ· {username}({user_id}) å¯¹è¯å†å²å·²é™åˆ¶ä¸º20è½®")
        
        # æ ¼å¼åŒ–ç”Ÿæˆæ—¶é—´
        if generation_time < 1:
            time_str = f"{generation_time*1000:.0f}ms"
        else:
            time_str = f"{generation_time:.2f}s"
        
        # å‘é€ AI å›å¤ï¼Œæ”¯æŒé•¿æ¶ˆæ¯åˆ†å‰²
        await send_ai_response(update, ai_response, time_str)
        
        # è®°å½•å¯¹è¯å®Œæˆ
        conversation_logger.info(f"[ç”¨æˆ· {username}({user_id})] ç¬¬{conversation_round}è½®å¯¹è¯å®Œæˆ - å†å²è®°å½•é•¿åº¦: {len(conversation_history)}")
        
    except Exception as e:
        logger.error(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
        conversation_logger.error(f"[ç”¨æˆ· {username}({user_id})] ç¬¬{conversation_round}è½®å¯¹è¯å‡ºé”™: {str(e)}")
        await thinking_message.edit_text("æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶å‡ºç°é”™è¯¯ã€‚è¯·ç¨åé‡è¯•ã€‚")

async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """é”™è¯¯å¤„ç†å™¨"""
    logger.error(f"å¤„ç†æ›´æ–°æ—¶å‡ºé”™: {context.error}")
    if update and update.effective_message:
        try:
            await update.effective_message.reply_text("æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶å‡ºç°é”™è¯¯ã€‚è¯·ç¨åé‡è¯•ã€‚")
        except Exception as e:
            logger.error(f"å‘é€é”™è¯¯æ¶ˆæ¯å¤±è´¥: {str(e)}")

def main() -> None:
    """ä¸»å‡½æ•°"""
    if not TELEGRAM_BOT_TOKEN:
        logger.error("æœªè®¾ç½® TELEGRAM_BOT_TOKEN ç¯å¢ƒå˜é‡")
        return

    # åˆ›å»ºåº”ç”¨
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    # æ·»åŠ é”™è¯¯å¤„ç†å™¨
    application.add_error_handler(error_handler)

    # æ·»åŠ å¤„ç†å™¨
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("model", model_command))
    application.add_handler(CommandHandler("forget", forget_command))
    application.add_handler(CallbackQueryHandler(button_callback))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # å¯åŠ¨æœºå™¨äºº
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main() 